{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "#from itertools import permutations\n",
    "from collections import Counter\n",
    "from math import ceil\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "#from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import rankdata\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(from_, to_, incl_rect=True):\n",
    "    \n",
    "    years = [y for y in range(from_, to_+1)]\n",
    "    \n",
    "    variables = [f\"frq_{y}\" for y in years]\n",
    "    variables.extend([f\"fpm_{y}\" for y in years])\n",
    "    variables.extend([f\"gch_{y}:{y+1}\" for y in years[:-1]])\n",
    "    if incl_rect:\n",
    "        variables.extend([f\"rch_{y}:{y+1}\" for y in years[:-1]])\n",
    "    \n",
    "    years = [str(y) for y in years]\n",
    "    \n",
    "    return variables, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of terms in original dataset\n",
    "terms = [\n",
    "#'N1_kulturberikare',\n",
    "'V1_berika',\n",
    "#'N1_berikare',\n",
    "'N1_globalist',\n",
    "#'V1_kulturberika',\n",
    "'N1_återvandring',\n",
    "#'V1_återvandra',\n",
    "#'A1_globalistisk',\n",
    "'N1_förortsgäng',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(\n",
    "    path,            # path to csv-file\n",
    "    variables,       # variables to include\n",
    "    terms,           # terms to include\n",
    "    min_freq=10,     # int for min. freq.\n",
    "    force=False,     # provide bool for sub-selection using predefined list\n",
    "    external=None,   # provide dict for sub-selction if force=True\n",
    "    drop_frq=False):  # drop frq after sub_selection, or not\n",
    "    \n",
    "    df = pd.read_csv(Path(path), sep=\";\", index_col = 0)\n",
    "    terms = [t for t in terms if t in df.index]\n",
    "    #print(terms)\n",
    "    df = df[variables]\n",
    "    df = df.loc[terms]\n",
    "    \n",
    "    if min_freq != None:\n",
    "        years = [col.split(\"_\")[-1] for col in df.columns if col.startswith(\"frq_\")]\n",
    "        years.sort()\n",
    "        \n",
    "        for dwe in df.index:\n",
    "            for year in years:\n",
    "                \n",
    "                if force and dwe in external.keys():\n",
    "                    if int(year) in external[dwe]: \n",
    "                        if df.loc[dwe][f\"frq_{year}\"] < 10:\n",
    "                            print(\"For\", dwe, \"in\", year, \"change\", df.loc[dwe][f\"frq_{year}\"], \"to\", 10)\n",
    "                            df.at[dwe, f\"frq_{year}\"] = 10\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        df.at[dwe, f\"fpm_{year}\"] = np.nan\n",
    "                        if year == years[-1]:\n",
    "                            df.at[dwe, f\"gch_{int(year)-1}:{year}\"] = np.nan\n",
    "                            df.at[dwe, f\"rch_{int(year)-1}:{year}\"] = np.nan\n",
    "                        else:\n",
    "                            df.at[dwe, f\"gch_{year}:{int(year)+1}\"] = np.nan\n",
    "                            df.at[dwe, f\"rch_{year}:{int(year)+1}\"] = np.nan  \n",
    "                else:\n",
    "                    if df.loc[dwe][f\"frq_{year}\"] < min_freq: \n",
    "                        df.at[dwe, f\"fpm_{year}\"] = np.nan\n",
    "\n",
    "                        if year == years[-1]:\n",
    "                            df.at[dwe, f\"gch_{int(year)-1}:{year}\"] = np.nan\n",
    "                            df.at[dwe, f\"rch_{int(year)-1}:{year}\"] = np.nan\n",
    "                        else:\n",
    "                            df.at[dwe, f\"gch_{year}:{int(year)+1}\"] = np.nan\n",
    "                            df.at[dwe, f\"rch_{year}:{int(year)+1}\"] = np.nan                        \n",
    "    \n",
    "    if drop_frq:\n",
    "        df.drop([col for col in df.columns if col.startswith(\"frq_\")], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iod(path, ref_path, variables, terms, min_freq=10):\n",
    "    \n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "        \n",
    "    if type(ref_path) != pd.core.frame.DataFrame:\n",
    "        ref = get_df(ref_path, variables, terms, min_freq = None, drop_frq=False)\n",
    "    else:\n",
    "        ref = ref_path\n",
    "    \n",
    "    years = [col.split(\"_\")[-1] for col in ref.columns if col.startswith(\"frq_\")]\n",
    "        \n",
    "    if min_freq != None:\n",
    "        for dwe in ref.index:\n",
    "            for year in years:\n",
    "                if ref.loc[dwe][f\"frq_{year}\"] < min_freq:\n",
    "                    df.loc[df[\"DWE\"] == dwe, year] = np.nan    \n",
    "                    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_iod_dif(df, years):\n",
    "    transitions = [(y, str(int(y)+1)) for y in years[:-1]]\n",
    "    df = df.copy()\n",
    "    for yi, yj in transitions:\n",
    "        df[f\"{yi}:{yj}\"] = df[f\"{yj}\"] - df[f\"{yi}\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLLECT FLASHBACK DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables, years = get_variables(2000, 2022)\n",
    "\n",
    "# Where to find data for ...\n",
    "SBERT_LSC = \"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-bert-sentence-bert-swedish-cased.csv\"\n",
    "BERT_LSC  = \"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-bert-base-swedish-cased.csv\"\n",
    "MT5_LSC   = \"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-mt5-xl.csv\"\n",
    "\n",
    "SBERT_IOD = \"/home/max/Results/replacements/results/fb_kb_results.csv\"\n",
    "BERT_IOD  = \"/home/max/Results/replacements/results/fb_bert-kb-avg_results.csv\"\n",
    "MT5_IOD   = \"/home/max/Results/replacements/results/fb_mt5-xl_results.csv\"\n",
    "\n",
    "\n",
    "# Sentence-BERT\n",
    "fb_kb_lsc = get_df(SBERT_LSC, variables, terms)\n",
    "fb_kb_iod = get_iod(SBERT_IOD, SBERT_LSC, variables, terms)\n",
    "\n",
    "# BERT\n",
    "fb_bert_lsc = get_df(BERT_LSC, variables, terms)\n",
    "fb_bert_iod = get_iod(BERT_IOD, BERT_LSC, variables, terms)\n",
    "\n",
    "# mT5\n",
    "fb_mt5xl_lsc = get_df(MT5_LSC, variables, terms)\n",
    "fb_mt5xl_iod = get_iod(MT5_IOD, MT5_LSC, variables, terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WS=5\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_lsc_w5 = get_df(f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}.csv\", \n",
    "    variables_noRCH, terms, drop_frq = False)\n",
    "fb_sgns_w5_iod = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w{WS}_results.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w5_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS=10\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_lsc_w10 = get_df(f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}.csv\", \n",
    "    variables_noRCH, terms, drop_frq = False)\n",
    "fb_sgns_w10_iod = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w{WS}_results.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w10_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS=15\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_lsc_w15 = get_df(f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}.csv\", \n",
    "    variables_noRCH, terms, drop_frq = False)\n",
    "fb_sgns_w15_iod = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w{WS}_results.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w15_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WS=5\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_lsc_w5_200 = get_df(f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms, drop_frq = False)\n",
    "fb_sgns_w5_200_iod = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w{WS}-200_results.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w5_200_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WS=5\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_w5_200_iod_X = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w5-200-minimal_results_wsep.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w5_200_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WS=10\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_lsc_w10_200 = get_df(f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms, drop_frq = False)\n",
    "fb_sgns_w10_200_iod = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w{WS}-200_results.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w10_200_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WS=15\n",
    "variables_noRCH, _ = get_variables(2000, 2022, incl_rect=False)\n",
    "fb_sgns_lsc_w15_200 = get_df(f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms, drop_frq = False)\n",
    "fb_sgns_w15_200_iod = get_iod(f\"/home/max/Results/replacments_w5-15_d100-200/results/fb_sgns-w{WS}-200_results.csv\",\n",
    "    f\"/home/max/Documents/mlt/thesis/dw_results/fb_pol-yearly-radical3-restricted-w{WS}-200.csv\", \n",
    "    variables_noRCH, terms)\n",
    "fb_sgns_w15_200_iod.rename(columns={\"B-strategy\": \"B-Strategy\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add IOD difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_kb_iod     = add_iod_dif(fb_kb_iod, years) # Sentence-BERT\n",
    "fb_bert_iod     = add_iod_dif(fb_bert_iod, years)\n",
    "fb_mt5xl_iod    = add_iod_dif(fb_mt5xl_iod, years)\n",
    "\n",
    "fb_sgns_w5_iod  = add_iod_dif(fb_sgns_w5_iod, years)\n",
    "fb_sgns_w10_iod = add_iod_dif(fb_sgns_w10_iod, years)\n",
    "fb_sgns_w15_iod = add_iod_dif(fb_sgns_w15_iod, years)\n",
    "\n",
    "fb_sgns_w5_200_iod   = add_iod_dif(fb_sgns_w5_200_iod,   years)\n",
    "fb_sgns_w10_200_iod  = add_iod_dif(fb_sgns_w10_200_iod,  years)\n",
    "fb_sgns_w15_200_iod  = add_iod_dif(fb_sgns_w15_200_iod,  years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2data(\n",
    "    iod_data, \n",
    "    lsc_data, \n",
    "    dwes, \n",
    "    AB_strat, \n",
    "    years, \n",
    "    methods, \n",
    "    baseline=\"first\", \n",
    "    add_log_fpm=True, \n",
    "    add_freq_dif=True,\n",
    "    LOG = np.log2\n",
    "):\n",
    "    \n",
    "    df = iod_data.copy()\n",
    "    \n",
    "    df = df[df[\"DWE\"].isin(dwes)]\n",
    "\n",
    "    assert type(AB_strat) == dict\n",
    "        \n",
    "    for var, val in AB_strat.items():\n",
    "        df = df[df[var]==val]\n",
    "    \n",
    "    df.drop(AB_strat.keys(), axis=1, inplace=True)\n",
    "    \n",
    "    transitions = [(year, str(int(year)+1)) for year in years[:-1]]\n",
    "    \n",
    "    lscs = [\"fpm\", \"gch\", \"rch\"]\n",
    "    if add_freq_dif:\n",
    "        lscs = lscs + [\"fdf\", \"adf\", \"fpc\", \"apc\"]\n",
    "        lsc_data = lsc_data.copy()\n",
    "        for yi, yj in transitions:\n",
    "            lsc_data[f\"fdf_{yi}:{yj}\"] = lsc_data[f\"fpm_{yj}\"] - lsc_data[f\"fpm_{yi}\"] \n",
    "        for yi, yj in transitions:\n",
    "            lsc_data[f\"adf_{yi}:{yj}\"] = abs(lsc_data[f\"fpm_{yj}\"] - lsc_data[f\"fpm_{yi}\"]) \n",
    "        for yi, yj in transitions:\n",
    "            lsc_data[f\"fpc_{yi}:{yj}\"] = (lsc_data[f\"fpm_{yj}\"] - lsc_data[f\"fpm_{yi}\"]) / lsc_data[f\"fpm_{yi}\"]\n",
    "        for yi, yj in transitions:\n",
    "            lsc_data[f\"apc_{yi}:{yj}\"] = abs((lsc_data[f\"fpm_{yj}\"] - lsc_data[f\"fpm_{yi}\"]) / lsc_data[f\"fpm_{yi}\"])\n",
    "        \n",
    "    transitions = [f\"{yi}:{yj}\" for yi, yj in transitions]\n",
    "    \n",
    "    if baseline == \"first\":\n",
    "        years = years[:-1]\n",
    "    if baseline == \"second\":\n",
    "        years = years[1:]\n",
    "        \n",
    "    new_df = []\n",
    "    dw_yrs = []\n",
    "    for method in methods:\n",
    "        s    = df[df[\"Method\"]==method][[\"DWE\"]+years].set_index(\"DWE\").sort_index()\n",
    "        idx  = [dw for lst in [[dw]*len(years) for dw in s.index] for dw in lst]\n",
    "        yrs  = years*len(s.index)\n",
    "        dw_yrs.append(pd.Series([f\"{dw}_{y}\" for dw, y in zip(idx, yrs)], name=method))\n",
    "        new_df.append(pd.Series(s.to_numpy().flatten(), name=method))\n",
    "        \n",
    "    for method in methods: \n",
    "        s   = df[df[\"Method\"]==method][[\"DWE\"]+transitions].set_index(\"DWE\").sort_index()\n",
    "        idx = [dw for lst in [[dw]*len(transitions) for dw in s.index] for dw in lst]\n",
    "        trs  = transitions*len(s.index)\n",
    "        dw_yrs.append(pd.Series([f\"{dw}_{y}\" for dw, y in zip(idx, trs)], name=method+\"_dif\"))\n",
    "        new_df.append(pd.Series(s.to_numpy().flatten(), name=method+\"_dif\"))\n",
    "    \n",
    "    for lsc_measure in lscs:\n",
    "        if lsc_measure == \"fpm\":\n",
    "            variables = [col for col in lsc_data.columns if col.startswith(\"fpm\") and col.split(\"_\")[-1] in years]\n",
    "            s = lsc_data.loc[dwes][variables].sort_index()\n",
    "            idx  = [dw for lst in [[dw]*len(years) for dw in s.index] for dw in lst]\n",
    "            yrs  = years*len(s.index)\n",
    "            dw_yrs.append(pd.Series([f\"{dw}_{y}\" for dw, y in zip(idx, yrs)], name=lsc_measure))\n",
    "            new_df.append(pd.Series(s.to_numpy().flatten(), name=lsc_measure))\n",
    "            if add_log_fpm:\n",
    "                new_df.append(pd.Series(LOG(s.to_numpy().flatten()), name=lsc_measure+\"_log\"))\n",
    "            \n",
    "        else:\n",
    "            variables = [col for col in lsc_data.columns if col.startswith(lsc_measure)]\n",
    "            s = lsc_data.loc[dwes][variables].sort_index()\n",
    "            idx = [dw for lst in [[dw]*len(transitions) for dw in s.index] for dw in lst]\n",
    "            trs  = trs*len(s.index)\n",
    "            dw_yrs.append(pd.Series([f\"{dw}_{y}\" for dw, y in zip(idx, trs)], name=lsc_measure))\n",
    "            new_df.append(pd.Series(s.to_numpy().flatten(), name=lsc_measure))\n",
    "    \n",
    "    check = pd.concat(dw_yrs, axis=1)\n",
    "    \n",
    "    if False in (check[methods].eq(check[\"fpm\"], axis=0)).all(axis=1):\n",
    "        print(\"No match\")\n",
    "    \n",
    "    if False in (check[[col for col in check.columns if col.endswith(\"dif\")]].eq(check[[\"gch\",\"rch\"]], axis=0)).all(axis=1):\n",
    "        print(\"No match\")\n",
    "        \n",
    "    data = pd.concat(new_df+[check[\"fpm\"].rename(\"DW-YR\")], axis=1)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(data, DEP, INDEP, transform_dep=False, dep_transformer=None, LOG=np.log2): \n",
    "    \n",
    "    df = data[[DEP]+INDEP].copy()\n",
    "    df = df.dropna(axis=0)\n",
    "    \n",
    "    X = df[INDEP]\n",
    "    y = df[DEP]\n",
    "    \n",
    "    if transform_dep: \n",
    "        if dep_transformer == None:\n",
    "            y = LOG(y)\n",
    "        elif dep_transformer == \"rank\":\n",
    "            y = rankdata(y)\n",
    "        else:\n",
    "            y = y.values.reshape(-1,1)\n",
    "            if dep_transformer == \"box-cox\":\n",
    "                transformer = PowerTransformer(method='box-cox')\n",
    "                y = transformer.fit_transform(y)\n",
    "                print(\"Lambda = \", transformer.lambdas_[0])\n",
    "            elif dep_transformer == \"yeo-johnson\":\n",
    "                y = power_transform(y, method='yeo-johnson')\n",
    "            else:\n",
    "                transformer = dep_transformer\n",
    "                y = transformer.fit_transform(y)\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X, missing=\"drop\").fit()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_data(data, indep, dep, iod_var, log_iod=False, LOG=np.log2):\n",
    "    \n",
    "    data = data[indep+[dep]]\n",
    "    data = data.dropna()\n",
    "    data[iod_var] = abs(data[iod_var])\n",
    "    if log_iod:\n",
    "        data[iod_var] = LOG(data[iod_var])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VIF(data, dep):\n",
    "    exog_data_const = sm.add_constant(data[[c for c in data.columns if c != dep]])\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF Factor\"] = [variance_inflation_factor(exog_data_const.values, i) for i in range(exog_data_const.shape[1])]\n",
    "    vif = vif.transpose()\n",
    "    vif.columns = exog_data_const.columns\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normality_multi( # test assumptions\n",
    "    names, # list\n",
    "    iods, # list\n",
    "    lscs, # list\n",
    "    dep, \n",
    "    indep, \n",
    "    iod_var, \n",
    "    dwes, \n",
    "    abstrats, # list \n",
    "    years, \n",
    "    methods, \n",
    "    baseline, \n",
    "    log_transform,\n",
    "    log_transform_iod = False,\n",
    "    test_stat = \"jarque_bera\", \n",
    "    LOG=np.log2\n",
    "):\n",
    "    resids = []\n",
    "    VIFs = []\n",
    "    \n",
    "    if iod_var not in indep:\n",
    "        indep.append(iod_var)\n",
    "    \n",
    "    for iod, lsc, abstrat in zip(iods, lscs, abstrats):\n",
    "    \n",
    "        data = data2data(\n",
    "            iod_data = iod, \n",
    "            lsc_data = lsc, \n",
    "            dwes     = dwes,\n",
    "            AB_strat = abstrat, \n",
    "            years    = years,\n",
    "            methods  = methods,\n",
    "            baseline = baseline\n",
    "            )\n",
    "        \n",
    "        data = revise_data(data, indep, dep, iod_var, log_iod=log_transform_iod, LOG=LOG)\n",
    "        \n",
    "        vif = VIF(data, dep)\n",
    "        VIFs.append(vif)\n",
    "\n",
    "        res = OLS(data, dep, indep, transform_dep=log_transform, LOG=LOG)#, dep_transformer=\"box-cox\" )\n",
    "        resids.append(res.resid)\n",
    "    \n",
    "    dfs = []\n",
    "    for r in resids:\n",
    "        normality_res = pg.normality(r, method=test_stat)\n",
    "        dfs.append(normality_res)\n",
    "        \n",
    "    df = pd.concat(dfs, axis = 0)\n",
    "    df.index = names\n",
    "    VIF_tab = pd.concat(VIFs)\n",
    "    VIF_tab.index = names\n",
    "    \n",
    "    return df, VIF_tab\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stargazer_multi(\n",
    "    names, # list\n",
    "    iods, # list\n",
    "    lscs, # list\n",
    "    dep, \n",
    "    indep, \n",
    "    iod_var, \n",
    "    dwes, \n",
    "    abstrats, # list \n",
    "    years, \n",
    "    methods, \n",
    "    baseline, \n",
    "    log_transform,\n",
    "    log_transform_iod = False,\n",
    "    #test_stat = \"jarque_bera\",\n",
    "    LOG=np.log2,\n",
    "    norm=False\n",
    "):\n",
    "    models = []\n",
    "    \n",
    "    if iod_var not in indep:\n",
    "        indep.append(iod_var)\n",
    "    \n",
    "    for iod, lsc, abstrat in zip(iods, lscs, abstrats):\n",
    "    \n",
    "        data = data2data(\n",
    "            iod_data = iod, \n",
    "            lsc_data = lsc, \n",
    "            dwes     = dwes,\n",
    "            AB_strat = abstrat, \n",
    "            years    = years,\n",
    "            methods  = methods,\n",
    "            baseline = baseline,\n",
    "            LOG=LOG\n",
    "            )\n",
    "        \n",
    "        data = revise_data(data, indep, dep, iod_var)\n",
    "        if log_transform:\n",
    "            data[dep] = LOG(data[dep])\n",
    "        if log_transform_iod:\n",
    "            data[iod_var] = LOG(data[iod_var])        \n",
    "                \n",
    "        if norm:\n",
    "            for c in data.columns:\n",
    "                data[c] = zscore(data[c])\n",
    "            \n",
    "        res = OLS(data, dep, indep)\n",
    "        models.append(res)\n",
    "    \n",
    "    ziggy = Stargazer(models)\n",
    "    ziggy.custom_columns(names)#, [1, 1])\n",
    "    ziggy.show_model_numbers(False)\n",
    "    ziggy.covariate_order(sorted(indep)+[\"const\"])\n",
    "    ziggy.rename_covariates({'cnt-ssc_dif': '$\\Delta ^{IOR}$', 'fpc':'$\\Delta ^{FPM}$', 'fpm_log': 'FPM (log)' })\n",
    "    ziggy.significance_levels([0.05, 0.01, 0.001])\n",
    "    \n",
    "    return ziggy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FB_LSC = [\n",
    "fb_kb_lsc,\n",
    "fb_bert_lsc,\n",
    "fb_mt5xl_lsc,\n",
    "fb_sgns_lsc_w5,\n",
    "fb_sgns_lsc_w10,\n",
    "fb_sgns_lsc_w15,\n",
    "fb_sgns_lsc_w5_200,\n",
    "fb_sgns_lsc_w10_200,\n",
    "fb_sgns_lsc_w15_200    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FB_IOD = [\n",
    "fb_kb_iod,\n",
    "fb_bert_iod,\n",
    "fb_mt5xl_iod,\n",
    "fb_sgns_w5_iod,\n",
    "fb_sgns_w10_iod,\n",
    "fb_sgns_w15_iod,\n",
    "fb_sgns_w5_200_iod,\n",
    "fb_sgns_w10_200_iod,\n",
    "fb_sgns_w15_200_iod\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "\"SBERT\", #\"fb_kb\",\n",
    "\"BERT\", #\"fb_bert\",\n",
    "\"mT5-XL\",\n",
    "\"SGNS-w5\",\n",
    "\"SGNS-w10\",\n",
    "\"SGNS-w15\",\n",
    "\"SGNS-w5-200\",\n",
    "\"SGNS-w10-200\",\n",
    "\"SGNS-w15-200\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slection strategies\n",
    "ABSTRATs = [{\"A-Strategy\":\"rn\"}] * 3 + [{\"A-Strategy\":\"ms1\", \"B-Strategy\":\"min0.2\"}] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEP_TRANSFORM = False\n",
    "IOD_TRANSFORM = False\n",
    "IOD_VAR = \"cnt-ssc_dif\"\n",
    "INDEP = [\n",
    "    IOD_VAR,\n",
    "    \"fpc\", \n",
    "#     \"fpm\"\n",
    "    \"fpm_log\"\n",
    "]\n",
    "LOG = np.log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table, vif = test_normality_multi(\n",
    "    names = names, # list\n",
    "    iods = ALL_FB_IOD, # list\n",
    "    lscs = ALL_FB_LSC, # list\n",
    "    dep = \"gch\", \n",
    "    indep = INDEP, \n",
    "    iod_var = IOD_VAR, \n",
    "    dwes = ['V1_berika', 'N1_globalist', 'N1_återvandring', 'N1_förortsgäng'], \n",
    "    abstrats = ABSTRATs, # list \n",
    "    years = years, \n",
    "    methods = [\"I-cnt\", \"O-cnt\", \"cnt-ssc\", \"cnt-smx\"], \n",
    "    baseline = \"first\", \n",
    "    log_transform = DEP_TRANSFORM,\n",
    "    log_transform_iod=IOD_TRANSFORM,\n",
    "#     test_stat = \"shapiro\" # \"jarque_bera\" (default),\n",
    "    LOG = LOG\n",
    ")\n",
    "table.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(table.to_latex(float_format=\"{:0.3f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_stars = stargazer_multi(\n",
    "    names = names, # list\n",
    "    iods = ALL_FB_IOD, # list\n",
    "    lscs = ALL_FB_LSC, # list\n",
    "    dep = \"gch\", \n",
    "    indep = INDEP, \n",
    "    iod_var = IOD_VAR, \n",
    "    dwes = ['V1_berika', 'N1_globalist', 'N1_återvandring', 'N1_förortsgäng'], \n",
    "    abstrats = ABSTRATs, # list \n",
    "    years = years, \n",
    "    methods = [\"I-cnt\", \"O-cnt\", \"cnt-ssc\", \"cnt-smx\"], \n",
    "    baseline = \"first\", \n",
    "    log_transform = DEP_TRANSFORM,\n",
    "    log_transform_iod=IOD_TRANSFORM,\n",
    "#     test_stat = \"shapiro\" # \"jarque_bera\" (default),\n",
    "    LOG=LOG,\n",
    "    norm = True\n",
    "); all_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(all_stars.render_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
